# Summary

OLAF (Open Life Science Analysis Framework) is a software platform that unites an Angular-based front-end with a Python-enabled Firebase backend to accelerate bioinformatics and computational biology workflows. By bundling these components in a Dockerized environment, OLAF ensures seamless local testing, straightforward deployment, and clear separation of concerns between the user interface and server-side processing. The platform’s design is deliberately modular, and it focuses on three core abstractions—agents, routers, and pipes—to implement complex data-processing pipelines in a manner that remains easy to understand and extend. These abstractions underscore OLAF’s commitment to a robust, maintainable, and test-friendly structure, offering researchers powerful tools to integrate advanced AI-driven analyses within an intuitive web interface.

# Statement of Need

Many bioinformatics projects rely heavily on custom scripts, ad hoc pipelines, or monolithic applications that are difficult to maintain and reproduce. As the scope of life-science research grows increasingly sophisticated—particularly with the introduction of large language models (LLMs) for tasks like gene annotation, literature mining, and sequence classification—there is a clear need for a framework that maintains clarity of design without compromising performance or ease of adoption. OLAF was conceived to bridge this gap. By uniting a modern web front-end (Angular) with a scalable serverless backend (Firebase Functions, written in Python), OLAF allows domain scientists to develop and share complex workflows without sacrificing modular design or reproducibility. Its Docker-based environment ensures that local and cloud-based testing scenarios remain consistent, thereby reducing “it works on my machine” issues and enhancing collaborative development.

# State of the Field

Bioinformatics ecosystems frequently offer standalone desktop applications or large, integrated portals with limited customization options. Projects such as Galaxy [@afgan2018galaxy] have successfully demonstrated the power of web-based platforms, but they often rely on heavier installations and unique frameworks, limiting how straightforwardly advanced AI components can be integrated. Meanwhile, libraries such as BioJS [@gomez2013biojs] have paved the way for web-based data visualization but do not directly address serverless or LLM-based workflows. OLAF extends this lineage by providing a well-defined, agent-oriented architecture for AI tasks, combined with a serverless design that leverages Firebase Cloud Functions. As a result, OLAF positions itself to meet researchers’ expanding needs for interactive, AI-enhanced data processing, offering a design pattern that remains comprehensible, testable, and suitable for local or cloud-based deployment.

# Implementation

OLAF is split into two major layers. The front-end is built in Angular, where features such as session management, interactive data uploads, and real-time result displays reside. Angular’s component-based design is used extensively to ensure a logical separation of views and data-handling services. The second layer is a Python-driven backend deployed as Firebase Cloud Functions, orchestrated through Docker for local testing and reproducibility. This backend includes three primary concepts:

**Agents**. Each agent encapsulates a distinct AI or transformation capability. An agent might interact with external APIs (such as OpenAI or a specialized bioinformatics service) or perform local computations. By confining decision-making and data transformation logic to dedicated agent classes, OLAF ensures that specialized tasks are simple to add and maintain.

**Routers**. The router layer receives session data from front-end requests, determines which agent should handle the request, and then organizes the flow of data among various pipes. If an agent’s response calls for chaining multiple operations, the router re-invokes itself with the new route. This design makes it clear and explicit how incoming data is processed, reduces duplication, and simplifies testing by isolating routing logic from agent logic.

**Pipes**. Pipes are asynchronous transformations that can be chained and reused to preprocess or postprocess data. For example, a pipe might scrub sensitive user input, attach domain-specific metadata, or handle rate-limiting for external APIs. By separating these responsibilities into well-defined components, OLAF maintains clarity and minimizes side effects throughout the processing pipeline.

The overall architecture is illustrated in Figure 2 (see suggested Python code below for generating a simple directed graph of the data flow). Because OLAF is designed to run under Docker locally, users and reviewers can easily spin up both the front-end (Angular’s development server) and the backend (Firebase Emulator or Docker container) to conduct end-to-end testing.

# Example Use Case

In a typical use case, a researcher might engage in a conversation asking OLAF to perform a series of steps for gene sequence analysis. The user first provides a short sequence to the system, requesting an annotation. OLAF’s Angular front-end presents this conversation as a series of chat-like messages. Behind the scenes, the Router receives session data and dispatches it to a specialized agent capable of sequence analysis, possibly calling external LLM-based libraries for advanced annotations (e.g., functional domain predictions or similarity searches). After the agent computes its responses, data pipes may trim extraneous symbols or filter untrusted content. If additional steps are necessary, the MasterAgent can prompt the Router to invoke another route (for example, a validation step or database write) before returning the final annotated result to the user’s browser. All of this is accomplished through a simple chat-like interface, lowering the barrier for domain scientists to run complex computations interactively.
