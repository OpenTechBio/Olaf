# Benchmarking Agent Prompts for Single-Cell Data Analysis

**⚠️ Work in Progress:** This tooling is currently under development. Its primary goal is to facilitate rapid iteration and testing of LLM agent prompts for analyzing single-cell transcriptomics datasets using a secure code execution sandbox.

## Overview

This framework provides the necessary tools to:

1. **Discover and Download Datasets:** Browse and fetch datasets (specifically from the CZI CELLxGENE Census) along with their metadata.
2. **Secure Code Execution:** Run Python code generated by an AI agent within an isolated Docker container (sandbox).
3. **Agent Interaction:** Orchestrate a "one-shot" interaction between an AI agent (powered by OpenAI's API), a selected dataset, and the code execution sandbox, allowing the agent a limited number of attempts to execute code for analysis.
4. **Prompt Iteration:** Easily test different agent prompts (pasted, from files, or from folders) against the same dataset and sandbox setup.

## Components

The framework consists of the following main components:

* **`.env` / `make_benchmarking_env.sh`:**
  * `make_benchmarking_env.sh`: An interactive script to securely prompt for and save your OpenAI API key.
  * `.env`: The file (created by the script) storing the `OPENAI_KEY`. This file should be added to your `.gitignore`.
* **`tools/czi_browser.py`:**
  * A CLI tool (with an interactive mode) for listing available CZI CELLxGENE Census versions and datasets.
  * Allows downloading specific datasets (`.h5ad` format) and their corresponding metadata (`.json` format) to the `datasets/` directory.
* **`sandbox/`:** Contains the code execution environment.
  * `Dockerfile`: Defines the Docker image based on `e2bdev/code-interpreter`, adding necessary Python/system dependencies (`pandas`, `anndata`, etc. via `requirements.txt`).
  * `requirements.txt`: Lists Python packages installed *inside* the sandbox container.
  * `startup.sh`: Script run when the container starts (e.g., to initialize Jupyter kernel if needed by the base image).
  * `benchmarking_sandbox_management.py`: A Python script (with CLI and interactive modes) to build the sandbox image, start/stop the container, and execute Python code strings within it via `docker exec`.
* **`datasets/`:** (Created by `czi_browser.py`)
  * Stores downloaded `.h5ad` data files and `.json` metadata files. This directory should likely be added to your `.gitignore` if datasets are large or numerous.
* **`OneShotAgentTester.py`:**
  * The main orchestrator script.
  * Prompts the user to select an agent prompt input method (paste, file, folder).
  * Lists datasets available in the `datasets/` directory and prompts for selection.
  * Asks for the maximum number of code execution attempts allowed for the agent.
  * Manages the interaction loop: starts the sandbox, copies data, sends prompts and history to the OpenAI API, executes code returned by the agent in the sandbox, and feeds results back to the agent until the attempt limit is reached.

## Setup

1. **Prerequisites:**

   * Python (3.8+ recommended)
   * `pip` (Python package installer)
   * Docker Desktop or Docker Engine (must be running)
   * Git (for cloning the repository)
2. **Install Top-Level Python Dependencies:**

   * Create and activate a Python virtual environment (recommended):
     ```bash
     python -m venv venv
     source venv/bin/activate  # Linux/macOS
     # venv\Scripts\activate  # Windows CMD
     ```
   * Install required packages for the host scripts:
     ```bash
     pip install -r requirements.txt
     ```
3. **Set OpenAI API Key:**

   * Make the script executable:
     ```bash
     chmod +x make_benchmarking_env.sh
     ```
   * Run the script and enter your key when prompted:
     ```bash
     ./make_benchmarking_env.sh
     ```
   * This creates the `.env` file. **Ensure `.env` is listed in your `.gitignore` file.**

4. **Prepare Sandbox Requirements:**

   * Edit `sandbox/requirements.txt` to include all the additional Python packages needed *inside* the container for agent code execution (e.g., `pandas`, `numpy`, `scipy`, `scikit-learn`, `anndata`, `matplotlib`, `seaborn`).

## Usage

1. **Download a Dataset:**

   * Navigate to the `tools/` directory: `cd tools`
   * Run the CZI browser interactively:
     ```bash
     python czi_browser.py
     ```
   * Use the `list-versions` and `list-datasets` commands to find a dataset ID.
   * Use the `download <version> <dataset_id>` command to download the data and metadata to the `benchmarking/datasets/` directory.
   * Return to the main `benchmarking/` directory: `cd ..`
2. **Run the Agent Tester:**

   * Execute the main tester script:
     ```bash
     python OneShotAgentTester.py
     ```
   * **Follow the prompts:**
     * Choose how to input your agent prompt (paste, single file, folder).
     * Select the downloaded dataset you want the agent to analyze.
     * Specify the maximum number of code execution attempts allowed.
   * The script will then start the sandbox, copy the data, and begin the interaction loop with the OpenAI API, displaying the conversation and code execution results.
   * If you provided a folder of prompts, it will iterate through each one.
3. **Manage Sandbox Manually (Optional):**

   * Navigate to the `sandbox/` directory: `cd sandbox`
   * Use `benchmarking_sandbox_management.py` for manual control:
     * Build image: `python benchmarking_sandbox_management.py build`
     * Start container: `python benchmarking_sandbox_management.py start`
     * Check status: `python benchmarking_sandbox_management.py status`
     * Run code: `python benchmarking_sandbox_management.py run "print('hello from sandbox')"`
     * Stop container: `python benchmarking_sandbox_management.py stop`
     * Run interactively: `python benchmarking_sandbox_management.py`
   * Return to the main `benchmarking/` directory: `cd ..`

## File Structure

```
benchmarking/
├── sandbox/
│   ├── Dockerfile
│   ├── startup.sh
│   ├── requirements.txt       # Requirements for INSIDE the container
│   └── benchmarking_sandbox_management.py
│
├── datasets/                  # Created by czi_browser.py download
│   └── <dataset_name>.h5ad
│   └── <dataset_name>.json
│   └── ...
│
├── tools/
│   └── czi_browser.py
│
├── make_benchmarking_env.sh  # used to make the .env file
├── OneShotAgentTester.py      # Main testing script
├── requirements.txt           # Requirements for host scripts (this file)
└── README.md                  # This file
└── .env                       # Stores API key (add to .gitignore)
```
